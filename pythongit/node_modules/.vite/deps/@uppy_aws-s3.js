import {
  AbortController as AbortController2,
  BasePlugin,
  ErrorWithCause_default,
  EventManager,
  RateLimitedQueue,
  UserFacingApiError_default,
  createAbortError,
  fetchWithNetworkError,
  filterFilesToEmitUploadStarted,
  filterNonFailedFiles,
  getAllowedMetaFields,
  getSocketHost
} from "./chunk-NBBH67XV.js";
import {
  __commonJS,
  __toESM
} from "./chunk-G3PMV62Z.js";

// node_modules/retry/lib/retry_operation.js
var require_retry_operation = __commonJS({
  "node_modules/retry/lib/retry_operation.js"(exports, module) {
    function RetryOperation(timeouts, options) {
      if (typeof options === "boolean") {
        options = { forever: options };
      }
      this._originalTimeouts = JSON.parse(JSON.stringify(timeouts));
      this._timeouts = timeouts;
      this._options = options || {};
      this._maxRetryTime = options && options.maxRetryTime || Infinity;
      this._fn = null;
      this._errors = [];
      this._attempts = 1;
      this._operationTimeout = null;
      this._operationTimeoutCb = null;
      this._timeout = null;
      this._operationStart = null;
      this._timer = null;
      if (this._options.forever) {
        this._cachedTimeouts = this._timeouts.slice(0);
      }
    }
    module.exports = RetryOperation;
    RetryOperation.prototype.reset = function() {
      this._attempts = 1;
      this._timeouts = this._originalTimeouts.slice(0);
    };
    RetryOperation.prototype.stop = function() {
      if (this._timeout) {
        clearTimeout(this._timeout);
      }
      if (this._timer) {
        clearTimeout(this._timer);
      }
      this._timeouts = [];
      this._cachedTimeouts = null;
    };
    RetryOperation.prototype.retry = function(err) {
      if (this._timeout) {
        clearTimeout(this._timeout);
      }
      if (!err) {
        return false;
      }
      var currentTime = (/* @__PURE__ */ new Date()).getTime();
      if (err && currentTime - this._operationStart >= this._maxRetryTime) {
        this._errors.push(err);
        this._errors.unshift(new Error("RetryOperation timeout occurred"));
        return false;
      }
      this._errors.push(err);
      var timeout = this._timeouts.shift();
      if (timeout === void 0) {
        if (this._cachedTimeouts) {
          this._errors.splice(0, this._errors.length - 1);
          timeout = this._cachedTimeouts.slice(-1);
        } else {
          return false;
        }
      }
      var self = this;
      this._timer = setTimeout(function() {
        self._attempts++;
        if (self._operationTimeoutCb) {
          self._timeout = setTimeout(function() {
            self._operationTimeoutCb(self._attempts);
          }, self._operationTimeout);
          if (self._options.unref) {
            self._timeout.unref();
          }
        }
        self._fn(self._attempts);
      }, timeout);
      if (this._options.unref) {
        this._timer.unref();
      }
      return true;
    };
    RetryOperation.prototype.attempt = function(fn, timeoutOps) {
      this._fn = fn;
      if (timeoutOps) {
        if (timeoutOps.timeout) {
          this._operationTimeout = timeoutOps.timeout;
        }
        if (timeoutOps.cb) {
          this._operationTimeoutCb = timeoutOps.cb;
        }
      }
      var self = this;
      if (this._operationTimeoutCb) {
        this._timeout = setTimeout(function() {
          self._operationTimeoutCb();
        }, self._operationTimeout);
      }
      this._operationStart = (/* @__PURE__ */ new Date()).getTime();
      this._fn(this._attempts);
    };
    RetryOperation.prototype.try = function(fn) {
      console.log("Using RetryOperation.try() is deprecated");
      this.attempt(fn);
    };
    RetryOperation.prototype.start = function(fn) {
      console.log("Using RetryOperation.start() is deprecated");
      this.attempt(fn);
    };
    RetryOperation.prototype.start = RetryOperation.prototype.try;
    RetryOperation.prototype.errors = function() {
      return this._errors;
    };
    RetryOperation.prototype.attempts = function() {
      return this._attempts;
    };
    RetryOperation.prototype.mainError = function() {
      if (this._errors.length === 0) {
        return null;
      }
      var counts = {};
      var mainError = null;
      var mainErrorCount = 0;
      for (var i = 0; i < this._errors.length; i++) {
        var error = this._errors[i];
        var message = error.message;
        var count = (counts[message] || 0) + 1;
        counts[message] = count;
        if (count >= mainErrorCount) {
          mainError = error;
          mainErrorCount = count;
        }
      }
      return mainError;
    };
  }
});

// node_modules/retry/lib/retry.js
var require_retry = __commonJS({
  "node_modules/retry/lib/retry.js"(exports) {
    var RetryOperation = require_retry_operation();
    exports.operation = function(options) {
      var timeouts = exports.timeouts(options);
      return new RetryOperation(timeouts, {
        forever: options && (options.forever || options.retries === Infinity),
        unref: options && options.unref,
        maxRetryTime: options && options.maxRetryTime
      });
    };
    exports.timeouts = function(options) {
      if (options instanceof Array) {
        return [].concat(options);
      }
      var opts = {
        retries: 10,
        factor: 2,
        minTimeout: 1 * 1e3,
        maxTimeout: Infinity,
        randomize: false
      };
      for (var key in options) {
        opts[key] = options[key];
      }
      if (opts.minTimeout > opts.maxTimeout) {
        throw new Error("minTimeout is greater than maxTimeout");
      }
      var timeouts = [];
      for (var i = 0; i < opts.retries; i++) {
        timeouts.push(this.createTimeout(i, opts));
      }
      if (options && options.forever && !timeouts.length) {
        timeouts.push(this.createTimeout(i, opts));
      }
      timeouts.sort(function(a, b) {
        return a - b;
      });
      return timeouts;
    };
    exports.createTimeout = function(attempt, opts) {
      var random = opts.randomize ? Math.random() + 1 : 1;
      var timeout = Math.round(random * Math.max(opts.minTimeout, 1) * Math.pow(opts.factor, attempt));
      timeout = Math.min(timeout, opts.maxTimeout);
      return timeout;
    };
    exports.wrap = function(obj, options, methods) {
      if (options instanceof Array) {
        methods = options;
        options = null;
      }
      if (!methods) {
        methods = [];
        for (var key in obj) {
          if (typeof obj[key] === "function") {
            methods.push(key);
          }
        }
      }
      for (var i = 0; i < methods.length; i++) {
        var method = methods[i];
        var original = obj[method];
        obj[method] = (function retryWrapper(original2) {
          var op = exports.operation(options);
          var args = Array.prototype.slice.call(arguments, 1);
          var callback = args.pop();
          args.push(function(err) {
            if (op.retry(err)) {
              return;
            }
            if (err) {
              arguments[0] = op.mainError();
            }
            callback.apply(this, arguments);
          });
          op.attempt(function() {
            original2.apply(obj, args);
          });
        }).bind(obj, original);
        obj[method].options = options;
      }
    };
  }
});

// node_modules/retry/index.js
var require_retry2 = __commonJS({
  "node_modules/retry/index.js"(exports, module) {
    module.exports = require_retry();
  }
});

// node_modules/p-retry/index.js
var import_retry = __toESM(require_retry2());

// node_modules/is-network-error/index.js
var objectToString = Object.prototype.toString;
var isError = (value) => objectToString.call(value) === "[object Error]";
var errorMessages = /* @__PURE__ */ new Set([
  "network error",
  // Chrome
  "Failed to fetch",
  // Chrome
  "NetworkError when attempting to fetch resource.",
  // Firefox
  "The Internet connection appears to be offline.",
  // Safari 16
  "Network request failed",
  // `cross-fetch`
  "fetch failed",
  // Undici (Node.js)
  "terminated",
  // Undici (Node.js)
  " A network error occurred.",
  // Bun (WebKit)
  "Network connection lost"
  // Cloudflare Workers (fetch)
]);
function isNetworkError(error) {
  const isValid = error && isError(error) && error.name === "TypeError" && typeof error.message === "string";
  if (!isValid) {
    return false;
  }
  const { message, stack } = error;
  if (message === "Load failed") {
    return stack === void 0 || "__sentry_captured__" in error;
  }
  if (message.startsWith("error sending request for url")) {
    return true;
  }
  return errorMessages.has(message);
}

// node_modules/p-retry/index.js
var AbortError = class extends Error {
  constructor(message) {
    super();
    if (message instanceof Error) {
      this.originalError = message;
      ({ message } = message);
    } else {
      this.originalError = new Error(message);
      this.originalError.stack = this.stack;
    }
    this.name = "AbortError";
    this.message = message;
  }
};
var decorateErrorWithCounts = (error, attemptNumber, options) => {
  const retriesLeft = options.retries - (attemptNumber - 1);
  error.attemptNumber = attemptNumber;
  error.retriesLeft = retriesLeft;
  return error;
};
async function pRetry(input, options) {
  return new Promise((resolve, reject) => {
    options = { ...options };
    options.onFailedAttempt ??= () => {
    };
    options.shouldRetry ??= () => true;
    options.retries ??= 10;
    const operation = import_retry.default.operation(options);
    const abortHandler = () => {
      operation.stop();
      reject(options.signal?.reason);
    };
    if (options.signal && !options.signal.aborted) {
      options.signal.addEventListener("abort", abortHandler, { once: true });
    }
    const cleanUp = () => {
      options.signal?.removeEventListener("abort", abortHandler);
      operation.stop();
    };
    operation.attempt(async (attemptNumber) => {
      try {
        const result = await input(attemptNumber);
        cleanUp();
        resolve(result);
      } catch (error) {
        try {
          if (!(error instanceof Error)) {
            throw new TypeError(`Non-error was thrown: "${error}". You should only throw errors.`);
          }
          if (error instanceof AbortError) {
            throw error.originalError;
          }
          if (error instanceof TypeError && !isNetworkError(error)) {
            throw error;
          }
          decorateErrorWithCounts(error, attemptNumber, options);
          if (!await options.shouldRetry(error)) {
            operation.stop();
            reject(error);
          }
          await options.onFailedAttempt(error);
          if (!operation.retry(error)) {
            throw operation.mainError();
          }
        } catch (finalError) {
          decorateErrorWithCounts(finalError, attemptNumber, options);
          cleanUp();
          reject(finalError);
        }
      }
    });
  });
}

// node_modules/@uppy/companion-client/package.json
var package_default = {
  name: "@uppy/companion-client",
  description: "Client library for communication with Companion. Intended for use in Uppy plugins.",
  version: "5.1.0",
  license: "MIT",
  type: "module",
  sideEffects: false,
  scripts: {
    build: "tsc --build tsconfig.build.json",
    typecheck: "tsc --build",
    test: "vitest run --environment=jsdom --silent='passed-only'"
  },
  keywords: [
    "file uploader",
    "uppy",
    "uppy-plugin",
    "companion",
    "provider"
  ],
  homepage: "https://uppy.io",
  bugs: {
    url: "https://github.com/transloadit/uppy/issues"
  },
  repository: {
    type: "git",
    url: "git+https://github.com/transloadit/uppy.git"
  },
  files: [
    "src",
    "lib",
    "dist",
    "CHANGELOG.md"
  ],
  exports: {
    ".": "./lib/index.js",
    "./package.json": "./package.json"
  },
  dependencies: {
    "@uppy/utils": "^7.1.0",
    "namespace-emitter": "^2.0.1",
    "p-retry": "^6.1.0"
  },
  devDependencies: {
    jsdom: "^26.1.0",
    typescript: "^5.8.3",
    vitest: "^3.2.4"
  },
  peerDependencies: {
    "@uppy/core": "^5.1.0"
  }
};

// node_modules/@uppy/companion-client/lib/AuthError.js
var AuthError = class extends Error {
  isAuthError;
  constructor() {
    super("Authorization required");
    this.name = "AuthError";
    this.isAuthError = true;
  }
};
var AuthError_default = AuthError;

// node_modules/@uppy/companion-client/lib/RequestClient.js
function stripSlash(url) {
  return url.replace(/\/$/, "");
}
var retryCount = 10;
var socketActivityTimeoutMs = 5 * 60 * 1e3;
var authErrorStatusCode = 401;
var HttpError = class extends Error {
  statusCode;
  constructor({ statusCode, message }) {
    super(message);
    this.name = "HttpError";
    this.statusCode = statusCode;
  }
};
async function handleJSONResponse(res) {
  if (res.status === authErrorStatusCode) {
    throw new AuthError_default();
  }
  if (res.ok) {
    return res.json();
  }
  let errMsg = `Failed request with status: ${res.status}. ${res.statusText}`;
  let errData;
  try {
    errData = await res.json();
    if (errData.message)
      errMsg = `${errMsg} message: ${errData.message}`;
    if (errData.requestId)
      errMsg = `${errMsg} request-Id: ${errData.requestId}`;
  } catch (cause) {
    throw new Error(errMsg, { cause });
  }
  if (res.status >= 400 && res.status <= 499 && errData.message) {
    throw new UserFacingApiError_default(errData.message);
  }
  throw new HttpError({ statusCode: res.status, message: errMsg });
}
function emitSocketProgress(uploader, progressData, file) {
  const { progress, bytesUploaded, bytesTotal } = progressData;
  if (progress) {
    uploader.uppy.log(`Upload progress: ${progress}`);
    uploader.uppy.emit("upload-progress", file, {
      uploadStarted: file.progress.uploadStarted ?? 0,
      bytesUploaded,
      bytesTotal
    });
  }
}
var RequestClient = class {
  static VERSION = package_default.version;
  #companionHeaders;
  uppy;
  opts;
  constructor(uppy, opts) {
    this.uppy = uppy;
    this.opts = opts;
    this.onReceiveResponse = this.onReceiveResponse.bind(this);
    this.#companionHeaders = opts.companionHeaders;
  }
  setCompanionHeaders(headers) {
    this.#companionHeaders = headers;
  }
  [/* @__PURE__ */ Symbol.for("uppy test: getCompanionHeaders")]() {
    return this.#companionHeaders;
  }
  get hostname() {
    const { companion } = this.uppy.getState();
    const host = this.opts.companionUrl;
    return stripSlash(companion?.[host] ? companion[host] : host);
  }
  async headers(emptyBody = false) {
    const defaultHeaders = {
      Accept: "application/json",
      ...emptyBody ? void 0 : {
        // Passing those headers on requests with no data forces browsers to first make a preflight request.
        "Content-Type": "application/json"
      }
    };
    return {
      ...defaultHeaders,
      ...this.#companionHeaders
    };
  }
  onReceiveResponse(res) {
    const { headers } = res;
    const state = this.uppy.getState();
    const companion = state.companion || {};
    const host = this.opts.companionUrl;
    if (headers.has("i-am") && headers.get("i-am") !== companion[host]) {
      this.uppy.setState({
        companion: { ...companion, [host]: headers.get("i-am") }
      });
    }
  }
  #getUrl(url) {
    if (/^(https?:|)\/\//.test(url)) {
      return url;
    }
    return `${this.hostname}/${url}`;
  }
  async request({ path, method = "GET", data, skipPostResponse, signal }) {
    try {
      const headers = await this.headers(!data);
      const response = await fetchWithNetworkError(this.#getUrl(path), {
        method,
        signal,
        headers,
        credentials: this.opts.companionCookiesRule || "same-origin",
        body: data ? JSON.stringify(data) : null
      });
      if (!skipPostResponse)
        this.onReceiveResponse(response);
      return await handleJSONResponse(response);
    } catch (err) {
      if (err.isAuthError || err.name === "UserFacingApiError" || err.name === "AbortError")
        throw err;
      throw new ErrorWithCause_default(`Could not ${method} ${this.#getUrl(path)}`, {
        cause: err
      });
    }
  }
  async get(path, options) {
    return this.request({ ...options, path });
  }
  async post(path, data, options) {
    return this.request({ ...options, path, method: "POST", data });
  }
  async delete(path, data, options) {
    return this.request({ ...options, path, method: "DELETE", data });
  }
  /**
   * Remote uploading consists of two steps:
   * 1. #requestSocketToken which starts the download/upload in companion and returns a unique token for the upload.
   * Then companion will halt the upload until:
   * 2. #awaitRemoteFileUpload is called, which will open/ensure a websocket connection towards companion, with the
   * previously generated token provided. It returns a promise that will resolve/reject once the file has finished
   * uploading or is otherwise done (failed, canceled)
   */
  async uploadRemoteFile(file, reqBody, options) {
    try {
      const { signal, getQueue } = options || {};
      return await pRetry(async () => {
        const existingServerToken = this.uppy.getFile(file.id)?.serverToken;
        if (existingServerToken != null) {
          this.uppy.log(`Connecting to exiting websocket ${existingServerToken}`);
          return this.#awaitRemoteFileUpload({
            file,
            queue: getQueue(),
            signal
          });
        }
        const queueRequestSocketToken = getQueue().wrapPromiseFunction(async (...args) => {
          try {
            return await this.#requestSocketToken(...args);
          } catch (outerErr) {
            if (outerErr.isAuthError)
              throw new AbortError(outerErr);
            if (outerErr.cause == null)
              throw outerErr;
            const err = outerErr.cause;
            const isRetryableHttpError = () => [408, 409, 429, 418, 423].includes(err.statusCode) || err.statusCode >= 500 && err.statusCode <= 599 && ![501, 505].includes(err.statusCode);
            if (err.name === "HttpError" && !isRetryableHttpError())
              throw new AbortError(err);
            throw err;
          }
        }, { priority: -1 });
        const serverToken = await queueRequestSocketToken({
          file,
          postBody: reqBody,
          signal
        }).abortOn(signal);
        if (!this.uppy.getFile(file.id))
          return void 0;
        this.uppy.setFileState(file.id, { serverToken });
        return this.#awaitRemoteFileUpload({
          file: this.uppy.getFile(file.id),
          // re-fetching file because it might have changed in the meantime
          queue: getQueue(),
          signal
        });
      }, {
        retries: retryCount,
        signal,
        onFailedAttempt: (err) => this.uppy.log(`Retrying upload due to: ${err.message}`, "warning")
      });
    } catch (err) {
      if (err.name === "AbortError") {
        return void 0;
      }
      this.uppy.emit("upload-error", file, err);
      throw err;
    }
  }
  #requestSocketToken = async ({ file, postBody, signal }) => {
    if (file.remote?.url == null) {
      throw new Error("Cannot connect to an undefined URL");
    }
    const res = await this.post(file.remote.url, {
      ...file.remote.body,
      ...postBody
    }, { signal });
    return res.token;
  };
  /**
   * This method will ensure a websocket for the specified file and returns a promise that resolves
   * when the file has finished downloading, or rejects if it fails.
   * It will retry if the websocket gets disconnected
   */
  async #awaitRemoteFileUpload({ file, queue, signal }) {
    let removeEventHandlers;
    const { capabilities } = this.uppy.getState();
    try {
      return await new Promise((resolve, reject) => {
        const token = file.serverToken;
        const host = getSocketHost(file.remote.companionUrl);
        let socket;
        let socketAbortController;
        let activityTimeout;
        let { isPaused } = file;
        const socketSend = (action, payload) => {
          if (socket == null || socket.readyState !== socket.OPEN) {
            this.uppy.log(`Cannot send "${action}" to socket ${file.id} because the socket state was ${String(socket?.readyState)}`, "warning");
            return;
          }
          socket.send(JSON.stringify({
            action,
            payload: payload ?? {}
          }));
        };
        function sendState() {
          if (!capabilities.resumableUploads)
            return;
          if (isPaused)
            socketSend("pause");
          else
            socketSend("resume");
        }
        const createWebsocket = async () => {
          if (socketAbortController)
            socketAbortController.abort();
          socketAbortController = new AbortController();
          const onFatalError = (err) => {
            this.uppy.setFileState(file.id, { serverToken: null });
            socketAbortController?.abort?.();
            reject(err);
          };
          function resetActivityTimeout() {
            clearTimeout(activityTimeout);
            if (isPaused)
              return;
            activityTimeout = setTimeout(() => onFatalError(new Error("Timeout waiting for message from Companion socket")), socketActivityTimeoutMs);
          }
          try {
            await queue.wrapPromiseFunction(async () => {
              const reconnectWebsocket = async () => new Promise((_, rejectSocket) => {
                socket = new WebSocket(`${host}/api/${token}`);
                resetActivityTimeout();
                socket.addEventListener("close", () => {
                  socket = void 0;
                  rejectSocket(new Error("Socket closed unexpectedly"));
                });
                socket.addEventListener("error", (error) => {
                  this.uppy.log(`Companion socket error ${JSON.stringify(error)}, closing socket`, "warning");
                  socket?.close();
                });
                socket.addEventListener("open", () => {
                  sendState();
                });
                socket.addEventListener("message", (e) => {
                  resetActivityTimeout();
                  try {
                    const { action, payload } = JSON.parse(e.data);
                    switch (action) {
                      case "progress": {
                        emitSocketProgress(this, payload, this.uppy.getFile(file.id));
                        break;
                      }
                      case "success": {
                        const text = payload.response?.responseText;
                        this.uppy.emit("upload-success", this.uppy.getFile(file.id), {
                          uploadURL: payload.url,
                          status: payload.response?.status ?? 200,
                          body: text ? JSON.parse(text) : void 0
                        });
                        socketAbortController?.abort?.();
                        resolve();
                        break;
                      }
                      case "error": {
                        const { message } = payload.error;
                        throw Object.assign(new Error(message), {
                          cause: payload.error
                        });
                      }
                      default:
                        this.uppy.log(`Companion socket unknown action ${action}`, "warning");
                    }
                  } catch (err) {
                    onFatalError(err);
                  }
                });
                const closeSocket = () => {
                  this.uppy.log(`Closing socket ${file.id}`);
                  clearTimeout(activityTimeout);
                  if (socket)
                    socket.close();
                  socket = void 0;
                };
                socketAbortController.signal.addEventListener("abort", () => {
                  closeSocket();
                });
              });
              await pRetry(reconnectWebsocket, {
                retries: retryCount,
                signal: socketAbortController.signal,
                onFailedAttempt: () => {
                  if (socketAbortController.signal.aborted)
                    return;
                  this.uppy.log(`Retrying websocket ${file.id}`);
                }
              });
            })().abortOn(socketAbortController.signal);
          } catch (err) {
            if (socketAbortController.signal.aborted)
              return;
            onFatalError(err);
          }
        };
        const pause = (newPausedState) => {
          if (!capabilities.resumableUploads)
            return;
          isPaused = newPausedState;
          if (socket)
            sendState();
        };
        const onFileRemove = (targetFile) => {
          if (!capabilities.individualCancellation)
            return;
          if (targetFile.id !== file.id)
            return;
          socketSend("cancel");
          socketAbortController?.abort?.();
          this.uppy.log(`upload ${file.id} was removed`);
          resolve();
        };
        const onCancelAll = () => {
          socketSend("cancel");
          socketAbortController?.abort?.();
          this.uppy.log(`upload ${file.id} was canceled`);
          resolve();
        };
        const onFilePausedChange = (targetFile, newPausedState) => {
          if (targetFile?.id !== file.id)
            return;
          pause(newPausedState);
        };
        const onPauseAll = () => pause(true);
        const onResumeAll = () => pause(false);
        this.uppy.on("file-removed", onFileRemove);
        this.uppy.on("cancel-all", onCancelAll);
        this.uppy.on("upload-pause", onFilePausedChange);
        this.uppy.on("pause-all", onPauseAll);
        this.uppy.on("resume-all", onResumeAll);
        removeEventHandlers = () => {
          this.uppy.off("file-removed", onFileRemove);
          this.uppy.off("cancel-all", onCancelAll);
          this.uppy.off("upload-pause", onFilePausedChange);
          this.uppy.off("pause-all", onPauseAll);
          this.uppy.off("resume-all", onResumeAll);
        };
        signal.addEventListener("abort", () => {
          socketAbortController?.abort();
        });
        createWebsocket();
      });
    } finally {
      removeEventHandlers?.();
    }
  }
};

// node_modules/@uppy/aws-s3/package.json
var package_default2 = {
  name: "@uppy/aws-s3",
  description: "Upload to Amazon S3 with Uppy",
  version: "5.0.1",
  license: "MIT",
  type: "module",
  sideEffects: false,
  scripts: {
    build: "tsc --build tsconfig.build.json",
    typecheck: "tsc --build",
    test: "vitest run --environment=jsdom --silent='passed-only'"
  },
  keywords: [
    "file uploader",
    "aws s3",
    "amazon s3",
    "s3",
    "uppy",
    "uppy-plugin",
    "multipart"
  ],
  homepage: "https://uppy.io",
  bugs: {
    url: "https://github.com/transloadit/uppy/issues"
  },
  repository: {
    type: "git",
    url: "git+https://github.com/transloadit/uppy.git"
  },
  files: [
    "src",
    "lib",
    "dist",
    "CHANGELOG.md"
  ],
  exports: {
    ".": "./lib/index.js",
    "./package.json": "./package.json"
  },
  dependencies: {
    "@uppy/companion-client": "^5.0.1",
    "@uppy/utils": "^7.0.2"
  },
  devDependencies: {
    "@aws-sdk/client-s3": "^3.362.0",
    "@aws-sdk/s3-request-presigner": "^3.362.0",
    "@uppy/core": "^5.0.2",
    jsdom: "^26.1.0",
    nock: "^13.1.0",
    typescript: "^5.8.3",
    vitest: "^3.2.4",
    "whatwg-fetch": "3.6.2"
  },
  peerDependencies: {
    "@uppy/core": "^5.0.2"
  }
};

// node_modules/@uppy/aws-s3/lib/createSignedURL.js
function createCanonicalRequest({ method = "PUT", CanonicalUri = "/", CanonicalQueryString = "", SignedHeaders, HashedPayload }) {
  const headerKeys = Object.keys(SignedHeaders).map((k) => k.toLowerCase()).sort();
  return [
    method,
    CanonicalUri,
    CanonicalQueryString,
    ...headerKeys.map((k) => `${k}:${SignedHeaders[k]}`),
    "",
    headerKeys.join(";"),
    HashedPayload
  ].join("\n");
}
var ec = new TextEncoder();
var algorithm = { name: "HMAC", hash: "SHA-256" };
async function digest(data) {
  const { subtle } = globalThis.crypto;
  return subtle.digest(algorithm.hash, ec.encode(data));
}
async function generateHmacKey(secret) {
  const { subtle } = globalThis.crypto;
  return subtle.importKey("raw", typeof secret === "string" ? ec.encode(secret) : secret, algorithm, false, ["sign"]);
}
function arrayBufferToHexString(arrayBuffer) {
  const byteArray = new Uint8Array(arrayBuffer);
  let hexString = "";
  for (let i = 0; i < byteArray.length; i++) {
    hexString += byteArray[i].toString(16).padStart(2, "0");
  }
  return hexString;
}
async function hash(key, data) {
  const { subtle } = globalThis.crypto;
  return subtle.sign(algorithm, await generateHmacKey(key), ec.encode(data));
}
async function createSignedURL({ accountKey, accountSecret, sessionToken, bucketName, Key, Region, expires, uploadId, partNumber }) {
  const Service = "s3";
  const host = `${Service}.${Region}.amazonaws.com`;
  const CanonicalUri = `/${bucketName}/${encodeURI(Key).replace(/[;?:@&=+$,#!'()*]/g, (c) => `%${c.charCodeAt(0).toString(16).toUpperCase()}`)}`;
  const payload = "UNSIGNED-PAYLOAD";
  const requestDateTime = (/* @__PURE__ */ new Date()).toISOString().replace(/[-:]|\.\d+/g, "");
  const date = requestDateTime.slice(0, 8);
  const scope = `${date}/${Region}/${Service}/aws4_request`;
  const url = new URL(`https://${host}${CanonicalUri}`);
  url.searchParams.set("X-Amz-Algorithm", "AWS4-HMAC-SHA256");
  url.searchParams.set("X-Amz-Content-Sha256", payload);
  url.searchParams.set("X-Amz-Credential", `${accountKey}/${scope}`);
  url.searchParams.set("X-Amz-Date", requestDateTime);
  url.searchParams.set("X-Amz-Expires", expires);
  url.searchParams.set("X-Amz-Security-Token", sessionToken);
  url.searchParams.set("X-Amz-SignedHeaders", "host");
  if (partNumber)
    url.searchParams.set("partNumber", partNumber);
  if (uploadId)
    url.searchParams.set("uploadId", uploadId);
  url.searchParams.set("x-id", partNumber && uploadId ? "UploadPart" : "PutObject");
  const canonical = createCanonicalRequest({
    CanonicalUri,
    CanonicalQueryString: url.search.slice(1),
    SignedHeaders: {
      host
    },
    HashedPayload: payload
  });
  const hashedCanonical = arrayBufferToHexString(await digest(canonical));
  const stringToSign = [
    `AWS4-HMAC-SHA256`,
    // The algorithm used to create the hash of the canonical request.
    requestDateTime,
    // The date and time used in the credential scope.
    scope,
    // The credential scope. This restricts the resulting signature to the specified Region and service.
    hashedCanonical
    // The hash of the canonical request.
  ].join("\n");
  const kDate = await hash(`AWS4${accountSecret}`, date);
  const kRegion = await hash(kDate, Region);
  const kService = await hash(kRegion, Service);
  const kSigning = await hash(kService, "aws4_request");
  const signature = arrayBufferToHexString(await hash(kSigning, stringToSign));
  url.searchParams.set("X-Amz-Signature", signature);
  return url;
}

// node_modules/@uppy/aws-s3/lib/MultipartUploader.js
var MB = 1024 * 1024;
var defaultOptions = {
  getChunkSize(file) {
    return Math.ceil(file.size / 1e4);
  },
  onProgress() {
  },
  onPartComplete() {
  },
  onSuccess() {
  },
  onError(err) {
    throw err;
  }
};
function ensureInt(value) {
  if (typeof value === "string") {
    return parseInt(value, 10);
  }
  if (typeof value === "number") {
    return value;
  }
  throw new TypeError("Expected a number");
}
var pausingUploadReason = /* @__PURE__ */ Symbol("pausing upload, not an actual error");
var MultipartUploader = class {
  options;
  #abortController = new AbortController2();
  #chunks = [];
  #chunkState = [];
  /**
   * The (un-chunked) data to upload.
   */
  #data;
  #file;
  #uploadHasStarted = false;
  #onError;
  #onSuccess;
  #shouldUseMultipart;
  #isRestoring;
  #onReject = (err) => err?.cause === pausingUploadReason ? null : this.#onError(err);
  #maxMultipartParts = 1e4;
  #minPartSize = 5 * MB;
  constructor(data, options) {
    this.options = {
      ...defaultOptions,
      ...options
    };
    this.options.getChunkSize ??= defaultOptions.getChunkSize;
    this.#data = data;
    this.#file = options.file;
    this.#onSuccess = this.options.onSuccess;
    this.#onError = this.options.onError;
    this.#shouldUseMultipart = this.options.shouldUseMultipart;
    this.#isRestoring = options.uploadId && options.key;
    this.#initChunks();
  }
  // initChunks checks the user preference for using multipart uploads (opts.shouldUseMultipart)
  // and calculates the optimal part size. When using multipart part uploads every part except for the last has
  // to be at least 5 MB and there can be no more than 10K parts.
  // This means we sometimes need to change the preferred part size from the user in order to meet these requirements.
  #initChunks() {
    const fileSize = this.#data.size;
    const shouldUseMultipart = typeof this.#shouldUseMultipart === "function" ? this.#shouldUseMultipart(this.#file) : Boolean(this.#shouldUseMultipart);
    if (shouldUseMultipart && fileSize > this.#minPartSize) {
      let chunkSize = Math.max(
        this.options.getChunkSize(this.#data),
        // Math.max can take undefined but TS does not think so
        this.#minPartSize
      );
      let arraySize = Math.floor(fileSize / chunkSize);
      if (arraySize > this.#maxMultipartParts) {
        arraySize = this.#maxMultipartParts;
        chunkSize = fileSize / this.#maxMultipartParts;
      }
      this.#chunks = Array(arraySize);
      for (let offset = 0, j = 0; offset < fileSize; offset += chunkSize, j++) {
        const end = Math.min(fileSize, offset + chunkSize);
        const getData = () => {
          const i2 = offset;
          return this.#data.slice(i2, end);
        };
        this.#chunks[j] = {
          getData,
          onProgress: this.#onPartProgress(j),
          onComplete: this.#onPartComplete(j),
          shouldUseMultipart
        };
        if (this.#isRestoring) {
          const size = offset + chunkSize > fileSize ? fileSize - offset : chunkSize;
          this.#chunks[j].setAsUploaded = () => {
            this.#chunks[j] = null;
            this.#chunkState[j].uploaded = size;
          };
        }
      }
    } else {
      this.#chunks = [
        {
          getData: () => this.#data,
          onProgress: this.#onPartProgress(0),
          onComplete: this.#onPartComplete(0),
          shouldUseMultipart
        }
      ];
    }
    this.#chunkState = this.#chunks.map(() => ({ uploaded: 0 }));
  }
  #createUpload() {
    this.options.companionComm.uploadFile(this.#file, this.#chunks, this.#abortController.signal).then(this.#onSuccess, this.#onReject);
    this.#uploadHasStarted = true;
  }
  #resumeUpload() {
    this.options.companionComm.resumeUploadFile(this.#file, this.#chunks, this.#abortController.signal).then(this.#onSuccess, this.#onReject);
  }
  #onPartProgress = (index) => (ev) => {
    if (!ev.lengthComputable)
      return;
    this.#chunkState[index].uploaded = ensureInt(ev.loaded);
    const totalUploaded = this.#chunkState.reduce((n, c) => n + c.uploaded, 0);
    this.options.onProgress(totalUploaded, this.#data.size);
  };
  #onPartComplete = (index) => (etag) => {
    this.#chunks[index] = null;
    this.#chunkState[index].etag = etag;
    this.#chunkState[index].done = true;
    const part = {
      PartNumber: index + 1,
      ETag: etag
    };
    this.options.onPartComplete(part);
  };
  #abortUpload() {
    this.#abortController.abort();
    this.options.companionComm.abortFileUpload(this.#file).catch((err) => this.options.log(err));
  }
  start() {
    if (this.#uploadHasStarted) {
      if (!this.#abortController.signal.aborted)
        this.#abortController.abort(pausingUploadReason);
      this.#abortController = new AbortController2();
      this.#resumeUpload();
    } else if (this.#isRestoring) {
      this.options.companionComm.restoreUploadFile(this.#file, {
        uploadId: this.options.uploadId,
        key: this.options.key
      });
      this.#resumeUpload();
    } else {
      this.#createUpload();
    }
  }
  pause() {
    this.#abortController.abort(pausingUploadReason);
    this.#abortController = new AbortController2();
  }
  abort(opts) {
    if (opts?.really)
      this.#abortUpload();
    else
      this.pause();
  }
  [/* @__PURE__ */ Symbol.for("uppy test: getChunkState")]() {
    return this.#chunkState;
  }
};
var MultipartUploader_default = MultipartUploader;

// node_modules/@uppy/aws-s3/lib/utils.js
function throwIfAborted(signal) {
  if (signal?.aborted) {
    throw createAbortError("The operation was aborted", {
      cause: signal.reason
    });
  }
}

// node_modules/@uppy/aws-s3/lib/HTTPCommunicationQueue.js
function removeMetadataFromURL(urlString) {
  const urlObject = new URL(urlString);
  urlObject.search = "";
  urlObject.hash = "";
  return urlObject.href;
}
var HTTPCommunicationQueue = class {
  #abortMultipartUpload;
  #cache = /* @__PURE__ */ new WeakMap();
  #createMultipartUpload;
  #fetchSignature;
  #getUploadParameters;
  #listParts;
  #previousRetryDelay;
  #requests;
  #retryDelays;
  #sendCompletionRequest;
  #setS3MultipartState;
  #uploadPartBytes;
  #getFile;
  constructor(requests, options, setS3MultipartState, getFile) {
    this.#requests = requests;
    this.#setS3MultipartState = setS3MultipartState;
    this.#getFile = getFile;
    this.setOptions(options);
  }
  setOptions(options) {
    const requests = this.#requests;
    if ("abortMultipartUpload" in options) {
      this.#abortMultipartUpload = requests.wrapPromiseFunction(options.abortMultipartUpload, { priority: 1 });
    }
    if ("createMultipartUpload" in options) {
      this.#createMultipartUpload = requests.wrapPromiseFunction(options.createMultipartUpload, { priority: -1 });
    }
    if ("signPart" in options) {
      this.#fetchSignature = requests.wrapPromiseFunction(options.signPart);
    }
    if ("listParts" in options) {
      this.#listParts = requests.wrapPromiseFunction(options.listParts);
    }
    if ("completeMultipartUpload" in options) {
      this.#sendCompletionRequest = requests.wrapPromiseFunction(options.completeMultipartUpload, { priority: 1 });
    }
    if ("retryDelays" in options) {
      this.#retryDelays = options.retryDelays ?? [];
    }
    if ("uploadPartBytes" in options) {
      this.#uploadPartBytes = requests.wrapPromiseFunction(options.uploadPartBytes, { priority: Infinity });
    }
    if ("getUploadParameters" in options) {
      this.#getUploadParameters = requests.wrapPromiseFunction(options.getUploadParameters);
    }
  }
  async #shouldRetry(err, retryDelayIterator) {
    const requests = this.#requests;
    const status = err?.source?.status;
    if (status == null) {
      return false;
    }
    if (status === 403 && err.message === "Request has expired") {
      if (!requests.isPaused) {
        if (requests.limit === 1 || this.#previousRetryDelay == null) {
          const next = retryDelayIterator.next();
          if (next == null || next.done) {
            return false;
          }
          this.#previousRetryDelay = next.value;
        }
        requests.rateLimit(0);
        await new Promise((resolve) => setTimeout(resolve, this.#previousRetryDelay));
      }
    } else if (status === 429) {
      if (!requests.isPaused) {
        const next = retryDelayIterator.next();
        if (next == null || next.done) {
          return false;
        }
        requests.rateLimit(next.value);
      }
    } else if (status > 400 && status < 500 && status !== 409) {
      return false;
    } else if (typeof navigator !== "undefined" && navigator.onLine === false) {
      if (!requests.isPaused) {
        requests.pause();
        window.addEventListener("online", () => {
          requests.resume();
        }, { once: true });
      }
    } else {
      const next = retryDelayIterator.next();
      if (next == null || next.done) {
        return false;
      }
      await new Promise((resolve) => setTimeout(resolve, next.value));
    }
    return true;
  }
  async getUploadId(file, signal) {
    let cachedResult;
    for (; ; ) {
      cachedResult = this.#cache.get(file.data);
      if (cachedResult == null)
        break;
      try {
        return await cachedResult;
      } catch {
      }
    }
    const promise = this.#createMultipartUpload(this.#getFile(file), signal);
    const abortPromise = () => {
      promise.abort(signal.reason);
      this.#cache.delete(file.data);
    };
    signal.addEventListener("abort", abortPromise, { once: true });
    this.#cache.set(file.data, promise);
    promise.then(async (result) => {
      signal.removeEventListener("abort", abortPromise);
      this.#setS3MultipartState(file, result);
      this.#cache.set(file.data, result);
    }, () => {
      signal.removeEventListener("abort", abortPromise);
      this.#cache.delete(file.data);
    });
    return promise;
  }
  async abortFileUpload(file) {
    const result = this.#cache.get(file.data);
    if (result == null) {
      return;
    }
    this.#cache.delete(file.data);
    this.#setS3MultipartState(file, /* @__PURE__ */ Object.create(null));
    let awaitedResult;
    try {
      awaitedResult = await result;
    } catch {
      return;
    }
    await this.#abortMultipartUpload(this.#getFile(file), awaitedResult);
  }
  async #nonMultipartUpload(file, chunk, signal) {
    const { method = "POST", url, fields, headers } = await this.#getUploadParameters(this.#getFile(file), {
      signal
    }).abortOn(signal);
    let body;
    const data = chunk.getData();
    if (method.toUpperCase() === "POST") {
      const formData = new FormData();
      Object.entries(fields).forEach(([key2, value]) => formData.set(key2, value));
      formData.set("file", data);
      body = formData;
    } else {
      body = data;
    }
    const { onProgress, onComplete } = chunk;
    const result = await this.#uploadPartBytes({
      signature: { url, headers, method },
      body,
      size: data.size,
      onProgress,
      onComplete,
      signal
    }).abortOn(signal);
    const key = fields?.key;
    this.#setS3MultipartState(file, { key });
    return {
      ...result,
      location: result.location ?? removeMetadataFromURL(url),
      bucket: fields?.bucket,
      key
    };
  }
  async uploadFile(file, chunks, signal) {
    throwIfAborted(signal);
    if (chunks.length === 1 && !chunks[0].shouldUseMultipart) {
      return this.#nonMultipartUpload(file, chunks[0], signal);
    }
    const { uploadId, key } = await this.getUploadId(file, signal);
    throwIfAborted(signal);
    try {
      const parts = await Promise.all(chunks.map((chunk, i) => this.uploadChunk(file, i + 1, chunk, signal)));
      throwIfAborted(signal);
      return await this.#sendCompletionRequest(this.#getFile(file), { key, uploadId, parts, signal }, signal).abortOn(signal);
    } catch (err) {
      if (err?.cause !== pausingUploadReason && err?.name !== "AbortError") {
        this.abortFileUpload(file);
      }
      throw err;
    }
  }
  restoreUploadFile(file, uploadIdAndKey) {
    this.#cache.set(file.data, uploadIdAndKey);
  }
  async resumeUploadFile(file, chunks, signal) {
    throwIfAborted(signal);
    if (chunks.length === 1 && chunks[0] != null && !chunks[0].shouldUseMultipart) {
      return this.#nonMultipartUpload(file, chunks[0], signal);
    }
    const { uploadId, key } = await this.getUploadId(file, signal);
    throwIfAborted(signal);
    const alreadyUploadedParts = await this.#listParts(this.#getFile(file), { uploadId, key, signal }, signal).abortOn(signal);
    throwIfAborted(signal);
    const parts = await Promise.all(chunks.map((chunk, i) => {
      const partNumber = i + 1;
      const alreadyUploadedInfo = alreadyUploadedParts.find(({ PartNumber }) => PartNumber === partNumber);
      if (alreadyUploadedInfo == null) {
        return this.uploadChunk(file, partNumber, chunk, signal);
      }
      chunk?.setAsUploaded?.();
      return { PartNumber: partNumber, ETag: alreadyUploadedInfo.ETag };
    }));
    throwIfAborted(signal);
    return this.#sendCompletionRequest(this.#getFile(file), { key, uploadId, parts, signal }, signal).abortOn(signal);
  }
  async uploadChunk(file, partNumber, chunk, signal) {
    throwIfAborted(signal);
    const { uploadId, key } = await this.getUploadId(file, signal);
    const signatureRetryIterator = this.#retryDelays.values();
    const chunkRetryIterator = this.#retryDelays.values();
    const shouldRetrySignature = () => {
      const next = signatureRetryIterator.next();
      if (next == null || next.done) {
        return null;
      }
      return next.value;
    };
    for (; ; ) {
      throwIfAborted(signal);
      const chunkData = chunk.getData();
      const { onProgress, onComplete } = chunk;
      let signature;
      try {
        signature = await this.#fetchSignature(this.#getFile(file), {
          // Always defined for multipart uploads
          uploadId,
          key,
          partNumber,
          body: chunkData,
          signal
        }).abortOn(signal);
      } catch (err) {
        const timeout = shouldRetrySignature();
        if (timeout == null || signal.aborted) {
          throw err;
        }
        await new Promise((resolve) => setTimeout(resolve, timeout));
        continue;
      }
      throwIfAborted(signal);
      try {
        return {
          PartNumber: partNumber,
          ...await this.#uploadPartBytes({
            signature,
            body: chunkData,
            size: chunkData.size,
            onProgress,
            onComplete,
            signal
          }).abortOn(signal)
        };
      } catch (err) {
        if (!await this.#shouldRetry(err, chunkRetryIterator))
          throw err;
      }
    }
  }
};

// node_modules/@uppy/aws-s3/lib/index.js
function assertServerError(res) {
  if (res?.error) {
    const error = new Error(res.message);
    Object.assign(error, res.error);
    throw error;
  }
  return res;
}
function getExpiry(credentials) {
  const expirationDate = credentials.Expiration;
  if (expirationDate) {
    const timeUntilExpiry = Math.floor((new Date(expirationDate) - Date.now()) / 1e3);
    if (timeUntilExpiry > 9) {
      return timeUntilExpiry;
    }
  }
  return void 0;
}
function getAllowedMetadata({ meta, allowedMetaFields, querify = false }) {
  const metaFields = allowedMetaFields ?? Object.keys(meta);
  if (!meta)
    return {};
  return Object.fromEntries(metaFields.filter((key) => meta[key] != null).map((key) => {
    const realKey = querify ? `metadata[${key}]` : key;
    const value = String(meta[key]);
    return [realKey, value];
  }));
}
var defaultOptions2 = {
  allowedMetaFields: true,
  limit: 6,
  getTemporarySecurityCredentials: false,
  shouldUseMultipart: ((file) => (file.size || 0) > 100 * 1024 * 1024),
  retryDelays: [0, 1e3, 3e3, 5e3]
};
var AwsS3Multipart = class _AwsS3Multipart extends BasePlugin {
  static VERSION = package_default2.version;
  #companionCommunicationQueue;
  #client;
  requests;
  uploaderEvents;
  uploaders;
  constructor(uppy, opts) {
    super(uppy, {
      ...defaultOptions2,
      uploadPartBytes: _AwsS3Multipart.uploadPartBytes,
      createMultipartUpload: null,
      listParts: null,
      abortMultipartUpload: null,
      completeMultipartUpload: null,
      signPart: null,
      getUploadParameters: null,
      ...opts
    });
    this.type = "uploader";
    this.id = this.opts.id || "AwsS3Multipart";
    this.#setClient(opts);
    const dynamicDefaultOptions = {
      createMultipartUpload: this.createMultipartUpload,
      listParts: this.listParts,
      abortMultipartUpload: this.abortMultipartUpload,
      completeMultipartUpload: this.completeMultipartUpload,
      signPart: opts?.getTemporarySecurityCredentials ? this.createSignedURL : this.signPart,
      getUploadParameters: opts?.getTemporarySecurityCredentials ? this.createSignedURL : this.getUploadParameters
    };
    for (const key of Object.keys(dynamicDefaultOptions)) {
      if (this.opts[key] == null) {
        this.opts[key] = dynamicDefaultOptions[key].bind(this);
      }
    }
    this.requests = this.opts.rateLimitedQueue ?? new RateLimitedQueue(this.opts.limit);
    this.#companionCommunicationQueue = new HTTPCommunicationQueue(this.requests, this.opts, this.#setS3MultipartState, this.#getFile);
    this.uploaders = /* @__PURE__ */ Object.create(null);
    this.uploaderEvents = /* @__PURE__ */ Object.create(null);
  }
  [/* @__PURE__ */ Symbol.for("uppy test: getClient")]() {
    return this.#client;
  }
  #setClient(opts) {
    if (opts == null || !("endpoint" in opts || "companionUrl" in opts || "headers" in opts || "companionHeaders" in opts || "cookiesRule" in opts || "companionCookiesRule" in opts))
      return;
    if ("companionUrl" in opts && !("endpoint" in opts)) {
      this.uppy.log("`companionUrl` option has been removed in @uppy/aws-s3, use `endpoint` instead.", "warning");
    }
    if ("companionHeaders" in opts && !("headers" in opts)) {
      this.uppy.log("`companionHeaders` option has been removed in @uppy/aws-s3, use `headers` instead.", "warning");
    }
    if ("companionCookiesRule" in opts && !("cookiesRule" in opts)) {
      this.uppy.log("`companionCookiesRule` option has been removed in @uppy/aws-s3, use `cookiesRule` instead.", "warning");
    }
    if ("endpoint" in opts) {
      this.#client = new RequestClient(this.uppy, {
        pluginId: this.id,
        provider: "AWS",
        companionUrl: this.opts.endpoint,
        companionHeaders: this.opts.headers,
        companionCookiesRule: this.opts.cookiesRule
      });
    } else {
      if ("headers" in opts) {
        this.#setCompanionHeaders();
      }
      if ("cookiesRule" in opts) {
        this.#client.opts.companionCookiesRule = opts.cookiesRule;
      }
    }
  }
  setOptions(newOptions) {
    this.#companionCommunicationQueue.setOptions(newOptions);
    super.setOptions(newOptions);
    this.#setClient(newOptions);
  }
  /**
   * Clean up all references for a file's upload: the MultipartUploader instance,
   * any events related to the file, and the Companion WebSocket connection.
   *
   * Set `opts.abort` to tell S3 that the multipart upload is cancelled and must be removed.
   * This should be done when the user cancels the upload, not when the upload is completed or errored.
   */
  resetUploaderReferences(fileID, opts) {
    if (this.uploaders[fileID]) {
      this.uploaders[fileID].abort({ really: opts?.abort || false });
      this.uploaders[fileID] = null;
    }
    if (this.uploaderEvents[fileID]) {
      this.uploaderEvents[fileID].remove();
      this.uploaderEvents[fileID] = null;
    }
  }
  #assertHost(method) {
    if (!this.#client) {
      throw new Error(`Expected a \`endpoint\` option containing a URL, or if you are not using Companion, a custom \`${method}\` implementation.`);
    }
  }
  createMultipartUpload(file, signal) {
    this.#assertHost("createMultipartUpload");
    throwIfAborted(signal);
    const allowedMetaFields = getAllowedMetaFields(this.opts.allowedMetaFields, file.meta);
    const metadata = getAllowedMetadata({ meta: file.meta, allowedMetaFields });
    return this.#client.post("s3/multipart", {
      filename: file.name,
      type: file.type,
      metadata
    }, { signal }).then(assertServerError);
  }
  listParts(file, { key, uploadId, signal }, oldSignal) {
    signal ??= oldSignal;
    this.#assertHost("listParts");
    throwIfAborted(signal);
    const filename = encodeURIComponent(key);
    return this.#client.get(`s3/multipart/${encodeURIComponent(uploadId)}?key=${filename}`, { signal }).then(assertServerError);
  }
  completeMultipartUpload(file, { key, uploadId, parts, signal }, oldSignal) {
    signal ??= oldSignal;
    this.#assertHost("completeMultipartUpload");
    throwIfAborted(signal);
    const filename = encodeURIComponent(key);
    const uploadIdEnc = encodeURIComponent(uploadId);
    return this.#client.post(`s3/multipart/${uploadIdEnc}/complete?key=${filename}`, { parts: parts.map(({ ETag, PartNumber }) => ({ ETag, PartNumber })) }, { signal }).then(assertServerError);
  }
  #cachedTemporaryCredentials;
  async #getTemporarySecurityCredentials(options) {
    throwIfAborted(options?.signal);
    if (this.#cachedTemporaryCredentials == null) {
      const { getTemporarySecurityCredentials } = this.opts;
      if (getTemporarySecurityCredentials === true) {
        this.#assertHost("getTemporarySecurityCredentials");
        this.#cachedTemporaryCredentials = this.#client.get("s3/sts", options).then(assertServerError);
      } else {
        this.#cachedTemporaryCredentials = getTemporarySecurityCredentials(options);
      }
      this.#cachedTemporaryCredentials = await this.#cachedTemporaryCredentials;
      setTimeout(() => {
        this.#cachedTemporaryCredentials = null;
      }, (getExpiry(this.#cachedTemporaryCredentials.credentials) || 0) * 500);
    }
    return this.#cachedTemporaryCredentials;
  }
  async createSignedURL(file, options) {
    const data = await this.#getTemporarySecurityCredentials(options);
    const expires = getExpiry(data.credentials) || 604800;
    const { uploadId, key, partNumber } = options;
    return {
      method: "PUT",
      expires,
      fields: {},
      url: `${await createSignedURL({
        accountKey: data.credentials.AccessKeyId,
        accountSecret: data.credentials.SecretAccessKey,
        sessionToken: data.credentials.SessionToken,
        expires,
        bucketName: data.bucket,
        Region: data.region,
        Key: key ?? `${crypto.randomUUID()}-${file.name}`,
        uploadId,
        partNumber
      })}`,
      // Provide content type header required by S3
      headers: {
        "Content-Type": file.type
      }
    };
  }
  signPart(file, { uploadId, key, partNumber, signal }) {
    this.#assertHost("signPart");
    throwIfAborted(signal);
    if (uploadId == null || key == null || partNumber == null) {
      throw new Error("Cannot sign without a key, an uploadId, and a partNumber");
    }
    const filename = encodeURIComponent(key);
    return this.#client.get(`s3/multipart/${encodeURIComponent(uploadId)}/${partNumber}?key=${filename}`, { signal }).then(assertServerError);
  }
  abortMultipartUpload(file, { key, uploadId, signal }) {
    this.#assertHost("abortMultipartUpload");
    const filename = encodeURIComponent(key);
    const uploadIdEnc = encodeURIComponent(uploadId);
    return this.#client.delete(`s3/multipart/${uploadIdEnc}?key=${filename}`, void 0, {
      signal
    }).then(assertServerError);
  }
  getUploadParameters(file, options) {
    this.#assertHost("getUploadParameters");
    const { meta } = file;
    const { type, name: filename } = meta;
    const allowedMetaFields = getAllowedMetaFields(this.opts.allowedMetaFields, file.meta);
    const metadata = getAllowedMetadata({
      meta,
      allowedMetaFields,
      querify: true
    });
    const query = new URLSearchParams({ filename, type, ...metadata });
    return this.#client.get(`s3/params?${query}`, options);
  }
  static async uploadPartBytes({ signature: { url, expires, headers, method = "PUT" }, body, size = body.size, onProgress, onComplete, signal }) {
    throwIfAborted(signal);
    if (url == null) {
      throw new Error("Cannot upload to an undefined URL");
    }
    return new Promise((resolve, reject) => {
      const xhr = new XMLHttpRequest();
      xhr.open(method, url, true);
      if (headers) {
        Object.keys(headers).forEach((key) => {
          xhr.setRequestHeader(key, headers[key]);
        });
      }
      xhr.responseType = "text";
      if (typeof expires === "number") {
        xhr.timeout = expires * 1e3;
      }
      function onabort() {
        xhr.abort();
      }
      function cleanup() {
        signal?.removeEventListener("abort", onabort);
      }
      signal?.addEventListener("abort", onabort);
      xhr.upload.addEventListener("progress", (ev) => {
        onProgress(ev);
      });
      xhr.addEventListener("abort", () => {
        cleanup();
        reject(createAbortError());
      });
      xhr.addEventListener("timeout", () => {
        cleanup();
        const error = new Error("Request has expired");
        error.source = { status: 403 };
        reject(error);
      });
      xhr.addEventListener("load", () => {
        cleanup();
        if (xhr.status === 403 && xhr.responseText.includes("<Message>Request has expired</Message>")) {
          const error = new Error("Request has expired");
          error.source = xhr;
          reject(error);
          return;
        }
        if (xhr.status < 200 || xhr.status >= 300) {
          const error = new Error("Non 2xx");
          error.source = xhr;
          reject(error);
          return;
        }
        onProgress?.({ loaded: size, lengthComputable: true });
        const arr = xhr.getAllResponseHeaders().trim().split(/[\r\n]+/);
        const headersMap = { __proto__: null };
        for (const line of arr) {
          const parts = line.split(": ");
          const header = parts.shift();
          const value = parts.join(": ");
          headersMap[header] = value;
        }
        const { etag, location: location2 } = headersMap;
        if (method.toUpperCase() === "POST" && location2 == null) {
          console.error("@uppy/aws-s3: Could not read the Location header. This likely means CORS is not configured correctly on the S3 Bucket. See https://uppy.io/docs/aws-s3/#setting-up-your-s3-bucket");
        }
        if (etag == null) {
          console.error("@uppy/aws-s3: Could not read the ETag header. This likely means CORS is not configured correctly on the S3 Bucket. See https://uppy.io/docs/aws-s3/#setting-up-your-s3-bucket");
          return;
        }
        onComplete?.(etag);
        resolve({
          ...headersMap,
          ETag: etag
          // keep capitalised ETag for backwards compatiblity
        });
      });
      xhr.addEventListener("error", (ev) => {
        cleanup();
        const error = new Error("Unknown error");
        error.source = ev.target;
        reject(error);
      });
      xhr.send(body);
    });
  }
  #setS3MultipartState = (file, { key, uploadId }) => {
    const cFile = this.uppy.getFile(file.id);
    if (cFile == null) {
      return;
    }
    this.uppy.setFileState(file.id, {
      s3Multipart: {
        ...cFile.s3Multipart,
        key,
        uploadId
      }
    });
  };
  #getFile = (file) => {
    return this.uppy.getFile(file.id) || file;
  };
  #uploadLocalFile(file) {
    return new Promise((resolve, reject) => {
      const onProgress = (bytesUploaded, bytesTotal) => {
        const latestFile = this.uppy.getFile(file.id);
        this.uppy.emit("upload-progress", latestFile, {
          uploadStarted: latestFile.progress.uploadStarted ?? 0,
          bytesUploaded,
          bytesTotal
        });
      };
      const onError = (err) => {
        this.uppy.log(err);
        this.uppy.emit("upload-error", file, err);
        this.resetUploaderReferences(file.id);
        reject(err);
      };
      const onSuccess = (result) => {
        const uploadResp = {
          body: {
            ...result
          },
          status: 200,
          uploadURL: result.location
        };
        this.resetUploaderReferences(file.id);
        this.uppy.emit("upload-success", this.#getFile(file), uploadResp);
        if (result.location) {
          this.uppy.log(`Download ${file.name} from ${result.location}`);
        }
        resolve(void 0);
      };
      const upload = new MultipartUploader_default(file.data, {
        // .bind to pass the file object to each handler.
        companionComm: this.#companionCommunicationQueue,
        log: (...args) => this.uppy.log(...args),
        getChunkSize: this.opts.getChunkSize ? this.opts.getChunkSize.bind(this) : void 0,
        onProgress,
        onError,
        onSuccess,
        onPartComplete: (part) => {
          this.uppy.emit("s3-multipart:part-uploaded", this.#getFile(file), part);
        },
        file,
        shouldUseMultipart: this.opts.shouldUseMultipart,
        ...file.s3Multipart
      });
      this.uploaders[file.id] = upload;
      const eventManager = new EventManager(this.uppy);
      this.uploaderEvents[file.id] = eventManager;
      eventManager.onFileRemove(file.id, (removed) => {
        upload.abort();
        this.resetUploaderReferences(file.id, { abort: true });
        resolve(`upload ${removed} was removed`);
      });
      eventManager.onCancelAll(file.id, () => {
        upload.abort();
        this.resetUploaderReferences(file.id, { abort: true });
        resolve(`upload ${file.id} was canceled`);
      });
      eventManager.onFilePause(file.id, (isPaused) => {
        if (isPaused) {
          upload.pause();
        } else {
          upload.start();
        }
      });
      eventManager.onPauseAll(file.id, () => {
        upload.pause();
      });
      eventManager.onResumeAll(file.id, () => {
        upload.start();
      });
      upload.start();
    });
  }
  #getCompanionClientArgs(file) {
    return {
      ...file.remote?.body,
      protocol: "s3-multipart",
      size: file.data.size,
      metadata: file.meta
    };
  }
  #upload = async (fileIDs) => {
    if (fileIDs.length === 0)
      return void 0;
    const files = this.uppy.getFilesByIds(fileIDs);
    const filesFiltered = filterNonFailedFiles(files);
    const filesToEmit = filterFilesToEmitUploadStarted(filesFiltered);
    this.uppy.emit("upload-start", filesToEmit);
    const promises = filesFiltered.map((file) => {
      if (file.isRemote) {
        const getQueue = () => this.requests;
        this.#setResumableUploadsCapability(false);
        const controller = new AbortController();
        const removedHandler = (removedFile) => {
          if (removedFile.id === file.id)
            controller.abort();
        };
        this.uppy.on("file-removed", removedHandler);
        const uploadPromise = this.uppy.getRequestClientForFile(file).uploadRemoteFile(file, this.#getCompanionClientArgs(file), {
          signal: controller.signal,
          getQueue
        });
        this.requests.wrapSyncFunction(() => {
          this.uppy.off("file-removed", removedHandler);
        }, { priority: -1 })();
        return uploadPromise;
      }
      return this.#uploadLocalFile(file);
    });
    const upload = await Promise.allSettled(promises);
    this.#setResumableUploadsCapability(true);
    return upload;
  };
  #setCompanionHeaders = () => {
    this.#client?.setCompanionHeaders(this.opts.headers);
  };
  #setResumableUploadsCapability = (boolean) => {
    const { capabilities } = this.uppy.getState();
    this.uppy.setState({
      capabilities: {
        ...capabilities,
        resumableUploads: boolean
      }
    });
  };
  #resetResumableCapability = () => {
    this.#setResumableUploadsCapability(true);
  };
  install() {
    this.#setResumableUploadsCapability(true);
    this.uppy.addPreProcessor(this.#setCompanionHeaders);
    this.uppy.addUploader(this.#upload);
    this.uppy.on("cancel-all", this.#resetResumableCapability);
  }
  uninstall() {
    this.uppy.removePreProcessor(this.#setCompanionHeaders);
    this.uppy.removeUploader(this.#upload);
    this.uppy.off("cancel-all", this.#resetResumableCapability);
  }
};
export {
  AwsS3Multipart as default
};
//# sourceMappingURL=@uppy_aws-s3.js.map
